{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a1edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "Web scraping is the process of extracting data from websites programmatically. It involves writing a script that sends HTTP requests to web pages, parses the HTML code of the page, and extracts the data from it.\n",
    "Web scraping is used to extract data from websites that don't provide APIs or other mechanisms for accessing their data.\n",
    "\n",
    "Here are three areas where web scraping is commonly used to get data:\n",
    "\n",
    "1.E-commerce: Web scraping can be used to extract pricing information, product descriptions, customer reviews, and other data from e-commerce websites. \n",
    "\n",
    "2.Social media: Web scraping can be used to extract data from social media platforms like Twitter, Facebook, and Instagram.\n",
    "This data can be used to monitor social media trends, analyze user behavior, and track brand mentions.\n",
    "\n",
    "3.Research: Web scraping can be used in academic research to gather data on a wide range of topics.\n",
    "For example, researchers might use web scraping to collect data on political candidates, analyze news coverage, or track the spread of diseases.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0bb93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "There are several methods used for web scraping:\n",
    "\n",
    "1.Manual web scraping: This involves manually copying and pasting data from websites into a spreadsheet or other document.\n",
    "\n",
    "2.Custom web scraping scripts: This involves writing custom scripts in a programming language like Python or JavaScript to automate the web scraping process.\n",
    "\n",
    "3.Web scraping tools: There are a number of web scraping tools available that allow users to extract data from websites without writing any code.\n",
    "These tools often have a visual interface and allow users to select the data they want to extract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071794c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Beautiful Soup is a Python library that is used for web scraping purposes. It provides a simple way to navigate and search the HTML and XML documents, making it easier to extract specific data from websites.\n",
    "It can parse HTML and XML files, as well as parse text data and files.\n",
    "\n",
    "Beautiful Soup is used in web scraping because it simplifies the process of parsing and navigating HTML and XML documents.\n",
    "It provides a simple API that allows users to search for specific tags and attributes, as well as navigate the document tree.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a8b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q4. Why is Flask used in this Web Scraping project?\n",
    "\n",
    "Flask is a lightweight web framework written in Python. It is used in this web scraping project to build a RESTful API that can be used to access the scraped data.\n",
    "Flask is a good choice for this project because it is easy to use, has a small footprint, and provides a simple way to build web APIs.\n",
    "\n",
    "Using Flask, we can build a web server that listens for HTTP requests and returns data in JSON format.\n",
    "This allows other applications to access the data scraped by our web scraping script.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01042c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "In this web scraping project, the following AWS services are used:\n",
    "\n",
    "1.Amazon EC2: This service is used to host the web scraping script and the Flask web server. EC2 provides scalable compute capacity in the cloud, allowing us to easily scale our resources up or down as needed.\n",
    "\n",
    "2.Amazon S3: This service is used to store the scraped data.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
